{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16adba27-27e9-4547-9f97-77a7f40cac6b",
   "metadata": {},
   "source": [
    "# Streaming chat completions - OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4c9e4-b77d-46f9-8799-7942e1e91080",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a863a-84b8-44fc-a326-218619e09e7e",
   "metadata": {},
   "source": [
    "Streaming chat completions from OpenAI allows you to get responses faster. Here's how it works:\n",
    "\n",
    "1. By default, OpenAI generates the full completion before sending it back. For long completions, this can take some time. \n",
    "\n",
    "2. To get responses sooner, enable streaming by setting `stream=True` when calling the chat completions API.\n",
    "3. Instead of one response, the API will return a stream of events as the completion is generated. \n",
    "4. Each event has a `delta` field containing a new chunk of text. Extract text from `delta` instead of `message`.\n",
    "5. As OpenAI generates the completion, your code can process these chunks incrementally rather than waiting for the full completion.\n",
    "6. This lets you print or display parts of the response before generation finishes.\n",
    "\n",
    "So in summary, streaming allows you to get partial responses immediately rather than waiting for the full completion. Enable it by setting `stream=True`, then extract text from the `delta` field of events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8868f-14bb-47d1-9a17-ab7179ed7f21",
   "metadata": {},
   "source": [
    "### Pros and Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60917f-7692-4657-b029-36f7a85ebfeb",
   "metadata": {},
   "source": [
    "Here is a 2 column markdown table with pros and cons of streaming chat completions:\n",
    "\n",
    "| Pros | Cons |\n",
    "|-|-|  \n",
    "| Faster responses | Harder to moderate content |\n",
    "| Low latency improves the UX | Increased complexity handling streaming events |\n",
    "| Really helpful for long completions | Potential errors if stream is interrupted/truncated |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0587a7-6ee4-4b76-b0e5-f07b8556830a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9556e-a555-46a3-8016-295fefc247a5",
   "metadata": {},
   "source": [
    "Install dependencies and import all the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01063b1a-68e4-455d-a442-9fbff5594b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222909a0-a3c9-4812-bf8c-08c281504f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b095f-b8a0-4e2d-9a9b-4568c68834df",
   "metadata": {},
   "source": [
    "### 1. Normal Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f355c8-115a-4c55-8faf-1d3a6f8f2b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response received 2.99 seconds after request\n",
      "Full response received:\n",
      "{\n",
      "  \"id\": \"chatcmpl-85fA3cR2hgF6gZknGPlxq9jKxvC8X\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696360555,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 40,\n",
      "    \"completion_tokens\": 136,\n",
      "    \"total_tokens\": 176\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to list all prime numbers up to 200\n",
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'List all prime numbers up to 200, with a comma between each number and no newlines. E.g., 2, 3, 5, ...'}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# calculate the taken \n",
    "response_time = time.time() - start_time\n",
    "\n",
    "# print the time delay and text received\n",
    "print(f\"Full response received {response_time:.2f} seconds after request\")\n",
    "print(f\"Full response received:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffc5780-d323-4b59-861b-0e0abb09a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02d5b6-973c-4a17-8013-b1726e15c47c",
   "metadata": {},
   "source": [
    "### 2. Streamed Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01877bd-13da-4e99-a120-cd350c95983b",
   "metadata": {},
   "source": [
    "Let's start by demonstrating how this works first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de88328a-2444-4b3f-b66d-4ae6d3b05d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-85fA7UAHPHdM4lYgmfjlrVBMr4lx5\",\n",
      "  \"object\": \"chat.completion.chunk\",\n",
      "  \"created\": 1696360559,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"delta\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\"\n",
      "      },\n",
      "      \"finish_reason\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"id\": \"chatcmpl-85fA7UAHPHdM4lYgmfjlrVBMr4lx5\",\n",
      "  \"object\": \"chat.completion.chunk\",\n",
      "  \"created\": 1696360559,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"delta\": {\n",
      "        \"content\": \"Paris\"\n",
      "      },\n",
      "      \"finish_reason\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"id\": \"chatcmpl-85fA7UAHPHdM4lYgmfjlrVBMr4lx5\",\n",
      "  \"object\": \"chat.completion.chunk\",\n",
      "  \"created\": 1696360559,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"delta\": {},\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_stream = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'Whats the capital of France? Answer in one word.'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True # by default, this is False\n",
    ")\n",
    "\n",
    "for chunk in response_stream:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dca864-c1b9-4c26-a3f9-3724712703a8",
   "metadata": {},
   "source": [
    "Now let's replicate the initial example, limiting progressively merging the streamed output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09589ce-51b4-4c99-a10d-3eef1de0be92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      ",\n",
      " \n",
      "3\n",
      ",\n",
      " \n",
      "5\n",
      ",\n",
      " \n",
      "7\n",
      ",\n",
      " \n",
      "11\n",
      ",\n",
      " \n",
      "13\n",
      ",\n",
      " \n",
      "17\n",
      ",\n",
      " \n",
      "19\n",
      ",\n",
      " \n",
      "23\n",
      ",\n",
      " \n",
      "29\n",
      ",\n",
      " \n",
      "31\n",
      ",\n",
      " \n",
      "37\n",
      ",\n",
      " \n",
      "41\n",
      ",\n",
      " \n",
      "43\n",
      ",\n",
      " \n",
      "47\n",
      ",\n",
      " \n",
      "53\n",
      ",\n",
      " \n",
      "59\n",
      ",\n",
      " \n",
      "61\n",
      ",\n",
      " \n",
      "67\n",
      ",\n",
      " \n",
      "71\n",
      ",\n",
      " \n",
      "73\n",
      ",\n",
      " \n",
      "79\n",
      ",\n",
      " \n",
      "83\n",
      ",\n",
      " \n",
      "89\n",
      ",\n",
      " \n",
      "97\n",
      ",\n",
      " \n",
      "101\n",
      ",\n",
      " \n",
      "103\n",
      ",\n",
      " \n",
      "107\n",
      ",\n",
      " \n",
      "109\n",
      ",\n",
      " \n",
      "113\n",
      ",\n",
      " \n",
      "127\n",
      ",\n",
      " \n",
      "131\n",
      ",\n",
      " \n",
      "137\n",
      ",\n",
      " \n",
      "139\n",
      ",\n",
      " \n",
      "149\n",
      ",\n",
      " \n",
      "151\n",
      ",\n",
      " \n",
      "157\n",
      ",\n",
      " \n",
      "163\n",
      ",\n",
      " \n",
      "167\n",
      ",\n",
      " \n",
      "173\n",
      ",\n",
      " \n",
      "179\n",
      ",\n",
      " \n",
      "181\n",
      ",\n",
      " \n",
      "191\n",
      ",\n",
      " \n",
      "193\n",
      ",\n",
      " \n",
      "197\n",
      ",\n",
      " \n",
      "199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to list all prime numbers up to 200\n",
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'List all prime numbers up to 200, with a comma between each number and no newlines. E.g., 2, 3, 5, ...'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "result_string = \"\" \n",
    "for delta in response:\n",
    "    delta_string=\"\"\n",
    "    if \"content\" in delta[\"choices\"][0][\"delta\"]:\n",
    "        delta_string = delta[\"choices\"][0][\"delta\"][\"content\"]\n",
    "    print(delta_string)\n",
    "    result_string += delta_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e336e1bb-3f8b-4c19-b32c-58d86844cc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199\n"
     ]
    }
   ],
   "source": [
    "print(result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f708e8-69f3-4fcd-85fe-2ca07af51c64",
   "metadata": {},
   "source": [
    "### 3. Streamed Chat Completion - Sentence-by-Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf3c66d5-f9b3-4351-8634-7714776c8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among other public buildings in a certain town, which for many reasons it will be prudent to refrain from mentioning, and to which I will assign no fictitious name, there is one anciently common to most towns, great or small: to wit, a workhouse; and in this workhouse was born; on a day and date which I need not trouble myself to repeat, inasmuch as it can be of no possible consequence to the reader, in this stage of the business at all events; the item of mortality whose name is prefixed to the head of this chapter.\n",
      "\n",
      "\n",
      "For a long time after it was ushered into this world of sorrow and trouble, by the parish surgeon, it remained a matter of considerable doubt whether the child would survive to bear any name at all; in which case it is somewhat more than probable that these memoirs would never have appeared; or, if they had, that being comprised within a couple of pages, they would have possessed the inestimable merit of being the most concise and faithful specimen of biography, extant in the literature of any age or country.\n",
      "\n",
      "\n",
      "Although I am not disposed to maintain that the being born in a workhouse, is in itself the most fortunate and enviable circumstance that can possibly befall a human being, I do mean to say that in this particular instance, it was the best thing for Oliver Twist that could by possibility have occurred. The fact is, that there was considerable difficulty in inducing Oliver to take upon himself the office of respiration,—a troublesome practice, but one which custom has rendered necessary to our easy existence; and for some time he lay gasping on a little flock mattress, rather unequally poised between this world and the next: the balance being decidedly in favour of the latter.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to list all prime numbers up to 200\n",
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'Return the first 3 paragraphs of oliver twist.'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "result_string = \"\" \n",
    "result_array = []\n",
    "for delta in response:\n",
    "    delta_string=\"\"\n",
    "    if \"content\" in delta[\"choices\"][0][\"delta\"]:\n",
    "        delta_string = delta[\"choices\"][0][\"delta\"][\"content\"]\n",
    "    result_string += delta_string\n",
    "    if any(map(result_string.__contains__, [f\"\\n\"])) or \"content\" not in delta[\"choices\"][0][\"delta\"]:\n",
    "        result_array.append(result_string)\n",
    "        print(result_string)\n",
    "        result_string = \"\"\n",
    "\n",
    "# if len(result_string) > 0:\n",
    "#     result_array.append(result_string)\n",
    "#     print(result_string)\n",
    "#     result_string = \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f1ea0df-8490-4d46-8e54-1a1f37ab5a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "377f12bb-ebbc-4190-a588-63e20e290b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Among other public buildings in a certain town, which for many reasons it will be prudent to refrain from mentioning, and to which I will assign no fictitious name, there is one anciently common to most towns, great or small: to wit, a workhouse; and in this workhouse was born; on a day and date which I need not trouble myself to repeat, inasmuch as it can be of no possible consequence to the reader, in this stage of the business at all events; the item of mortality whose name is prefixed to the head of this chapter.\\n\\n',\n",
       " 'For a long time after it was ushered into this world of sorrow and trouble, by the parish surgeon, it remained a matter of considerable doubt whether the child would survive to bear any name at all; in which case it is somewhat more than probable that these memoirs would never have appeared; or, if they had, that being comprised within a couple of pages, they would have possessed the inestimable merit of being the most concise and faithful specimen of biography, extant in the literature of any age or country.\\n\\n',\n",
       " 'Although I am not disposed to maintain that the being born in a workhouse, is in itself the most fortunate and enviable circumstance that can possibly befall a human being, I do mean to say that in this particular instance, it was the best thing for Oliver Twist that could by possibility have occurred. The fact is, that there was considerable difficulty in inducing Oliver to take upon himself the office of respiration,—a troublesome practice, but one which custom has rendered necessary to our easy existence; and for some time he lay gasping on a little flock mattress, rather unequally poised between this world and the next: the balance being decidedly in favour of the latter.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15230ad6-2ab5-40cf-8ca7-cc33ba119c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
